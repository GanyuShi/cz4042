{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import pylab as plt\n",
    "import multiprocessing as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4435, 37)\n",
      "(2000, 37)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('sat_train.txt', delimiter=' ', header=None)\n",
    "test = pd.read_csv('sat_test.txt', delimiter=' ', header=None)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train: (4435, 36)\n",
      "y train: (404, 1)\n",
      "x test: (2000, 36)\n",
      "y test: (102, 1)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "no_features = 36\n",
    "no_labels = 6\n",
    "no_iters = 2500\n",
    "\n",
    "seed = 10\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Load dataset\n",
    "x_train = train.iloc[:, :36]\n",
    "y_train_ = train.iloc[:, 36:36]\n",
    "x_test = test.iloc[:, :36]\n",
    "y_test_ = test.iloc[:, 36:36]\n",
    "\n",
    "print('x train:', x_train.shape)\n",
    "print('y train:',y_train.shape)\n",
    "print('x test:',x_test.shape)\n",
    "print('y test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train_.reshape(len(y_train_), no_labels)\n",
    "# y_test = y_test_.reshape(len(y_test_), no_labels)\n",
    "\n",
    "# # Scale data (training set) to 0 mean and unit standard deviation.\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffn(x, hidden_units):\n",
    "  \n",
    "  # Hidden\n",
    "    with tf.name_scope('hidden'):\n",
    "        weights = tf.Variable(\n",
    "          tf.truncated_normal([no_features, hidden_units],\n",
    "                                stddev=1.0 / np.sqrt(float(no_features))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden_units]),\n",
    "                             name='biases')\n",
    "        hidden = tf.nn.sigmoid(tf.matmul(x, weights) + biases)\n",
    "    \n",
    "  # Softmax\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([hidden_units, no_labels],\n",
    "                                stddev=1.0 / np.sqrt(float(hidden_units))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(tf.zeros([no_labels]),\n",
    "                             name='biases')\n",
    "        logits = tf.nn.softmax(hidden, weights) + biases\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(hidden_units):\n",
    "    x = tf.placeholder(tf.float32, [None, no_features])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_ = tf.placeholder(tf.float32, [None, no_labels])\n",
    "\n",
    "    # Build the graph for the deep net\n",
    "    y = ffn(x, hidden_units)\n",
    "\n",
    "    error = tf.reduce_mean(tf.reduce_sum(tf.square(y - y_), axis = 1))\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    te_err = []\n",
    "    for i in range(no_iters):\n",
    "        train.run(feed_dict={x: x_train, y_: y_train})\n",
    "\n",
    "        te_err.append(error.eval(feed_dict={x: x_test, y_: y_test}))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('%d: step %d, test error %g' % (hidden_units, i, te_err[i]))\n",
    "\n",
    "    return te_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    hidden_units = [1, 4, 16, 64]\n",
    "\n",
    "    no_threads = mp.cpu_count()\n",
    "    p = mp.Pool(processes = no_threads)\n",
    "    cost = p.map(my_train, hidden_units)\n",
    "\n",
    "    # plot learning curves\n",
    "    plt.figure(1)\n",
    "\n",
    "    min_cost = []\n",
    "    for h in range(len(hidden_units)):\n",
    "        plt.plot(range(no_iters), cost[h], label = 'hidden = {}'.format(hidden_units[h]))\n",
    "        min_cost.append(min(cost[h]))\n",
    "\n",
    "\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('mean square error')\n",
    "    plt.title('GD learning')\n",
    "    plt.legend()\n",
    "    plt.savefig('figures/5.3b_1.png')\n",
    "\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(hidden_units, min_cost)\n",
    "    plt.xlabel('number of hidden neurons')\n",
    "    plt.ylabel('test error')\n",
    "    plt.title('test error vs. number of hidden neurons')\n",
    "    plt.savefig('figures/5.3b_2.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 0 but is rank 2\n\t for 'limit' for 'softmax_linear/range' (op: 'Range') with input shapes: [], [4,6], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1576, in _create_c_op\n    c_op = c_api.TF_FinishOperation(op_desc)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 0 but is rank 2\n\t for 'limit' for 'softmax_linear/range' (op: 'Range') with input shapes: [], [4,6], [].\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-81-1acace03c5a9>\", line 8, in my_train\n    y = ffn(x, hidden_units)\n  File \"<ipython-input-80-8c6b1d279499>\", line 21, in ffn\n    logits = tf.nn.softmax(hidden, weights) + biases\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1738, in softmax\n    return _softmax(logits, gen_nn_ops.softmax, axis, name)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1690, in _softmax\n    logits = _swap_axis(logits, dim_axis, math_ops.subtract(input_rank, 1))\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1661, in _swap_axis\n    math_ops.range(dim_index), [last_index],\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1213, in range\n    return gen_math_ops._range(start, limit, delta, name=name)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 5745, in _range\n    \"Range\", start=start, limit=limit, delta=delta, name=name)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1731, in __init__\n    control_input_ops)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1579, in _create_c_op\n    raise ValueError(str(e))\nValueError: Shape must be rank 0 but is rank 2\n\t for 'limit' for 'softmax_linear/range' (op: 'Range') with input shapes: [], [4,6], [].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-0683678d11c2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mno_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# plot learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 0 but is rank 2\n\t for 'limit' for 'softmax_linear/range' (op: 'Range') with input shapes: [], [4,6], []."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4435, 36)\n",
      "(2000, 36)\n",
      "(4435, 6)\n",
      "(2000, 6)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"one_hot_4:0\", shape=(4435, 6), dtype=float32) which was passed to the feed with key Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-95-a7e7f1e053a2>\", line 100, in my_train\n    train.run(feed_dict={x: x_train, y_: y_train})\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2241, in run\n    _run_using_default_session(self, feed_dict, self.graph, session)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4986, in _run_using_default_session\n    session.run(operation, feed_dict)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 877, in run\n    run_metadata_ptr)\n  File \"/Users/shiganyu/anaconda3/envs/cz4042/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1051, in _run\n    'feed with key ' + str(feed) + '.')\nTypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"one_hot_4:0\", shape=(4435, 6), dtype=float32) which was passed to the feed with key Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32).\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-a7e7f1e053a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-a7e7f1e053a2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0mno_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m   \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# plot learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cz4042/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"one_hot_4:0\", shape=(4435, 6), dtype=float32) which was passed to the feed with key Tensor(\"Placeholder_1:0\", shape=(?, 6), dtype=float32)."
     ]
    }
   ],
   "source": [
    "#\n",
    "#   Chapter 5, example 3b\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import pylab as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "no_features = 36\n",
    "no_labels = 6\n",
    "no_iters = 2500\n",
    "\n",
    "seed = 10\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "\n",
    "# # Load dataset\n",
    "# boston = datasets.load_boston()\n",
    "# x, y = boston.data, boston.target\n",
    "\n",
    "# # Split dataset into train / test\n",
    "# x_train, x_test, y_train_, y_test_ = model_selection.train_test_split(\n",
    "# x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# y_train = y_train_.reshape(len(y_train_), no_labels)\n",
    "# y_test = y_test_.reshape(len(y_test_), no_labels)\n",
    "\n",
    "x_train = train.iloc[:, :36]\n",
    "y_train_ = train.iloc[:, 36]\n",
    "\n",
    "x_test = test.iloc[:, :36]\n",
    "y_test_ = test.iloc[:, 36]\n",
    "\n",
    "y_train = tf.one_hot(y_train_, no_labels)\n",
    "y_test = tf.one_hot(y_test_, no_labels)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Scale data (training set) to 0 mean and unit standard deviation.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "\n",
    "def ffn(x, hidden_units):\n",
    "  \n",
    "  # Hidden\n",
    "  with tf.name_scope('hidden'):\n",
    "    weights = tf.Variable(\n",
    "      tf.truncated_normal([no_features, hidden_units],\n",
    "                            stddev=1.0 / np.sqrt(float(no_features))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([hidden_units]),\n",
    "                         name='biases')\n",
    "    hidden = tf.nn.relu(tf.matmul(x, weights) + biases)\n",
    "    \n",
    "  # Linear\n",
    "  with tf.name_scope('softmax_linear'):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([hidden_units, no_labels],\n",
    "                            stddev=1.0 / np.sqrt(float(hidden_units))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([no_labels]),\n",
    "                         name='biases')\n",
    "    logits = tf.matmul(hidden, weights) + biases\n",
    "    \n",
    "  return logits\n",
    "\n",
    "\n",
    "def my_train(hidden_units):\n",
    "\n",
    "  x = tf.placeholder(tf.float32, [None, no_features])\n",
    "\n",
    "  # Define loss and optimizer\n",
    "  y_ = tf.placeholder(tf.float32, [None, no_labels])\n",
    "\n",
    "  # Build the graph for the deep net\n",
    "  y = ffn(x, hidden_units)\n",
    "\n",
    "  error = tf.reduce_mean(tf.reduce_sum(tf.square(y - y_), axis = 1))\n",
    "\n",
    "  train = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    te_err = []\n",
    "    for i in range(no_iters):\n",
    "      train.run(feed_dict={x: x_train, y_: y_train})\n",
    "\n",
    "      te_err.append(error.eval(feed_dict={x: x_test, y_: y_test}))\n",
    "\n",
    "      if i % 100 == 0:\n",
    "        print('%d: step %d, test error %g' % (hidden_units, i, te_err[i]))\n",
    "\n",
    "  return te_err\n",
    "               \n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "  hidden_units = [1, 4, 16, 64]\n",
    "\n",
    "  no_threads = mp.cpu_count()\n",
    "  p = mp.Pool(processes = no_threads)\n",
    "  cost = p.map(my_train, hidden_units)\n",
    "\n",
    "    # plot learning curves\n",
    "  plt.figure(1)\n",
    "\n",
    "  min_cost = []\n",
    "  for h in range(len(hidden_units)):\n",
    "    plt.plot(range(no_iters), cost[h], label = 'hidden = {}'.format(hidden_units[h]))\n",
    "    min_cost.append(min(cost[h]))\n",
    "\n",
    "\n",
    "  plt.xlabel('iterations')\n",
    "  plt.ylabel('mean square error')\n",
    "  plt.title('GD learning')\n",
    "  plt.legend()\n",
    "  plt.savefig('figures/5.3b_1.png')\n",
    "\n",
    "  \n",
    "  plt.figure(2)\n",
    "  plt.plot(hidden_units, min_cost)\n",
    "  plt.xlabel('number of hidden neurons')\n",
    "  plt.ylabel('test error')\n",
    "  plt.title('test error vs. number of hidden neurons')\n",
    "  plt.savefig('figures/5.3b_2.png')\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cz4042]",
   "language": "python",
   "name": "conda-env-cz4042-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
