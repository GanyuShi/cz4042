{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (20640, 9)\n",
      "First row:\n",
      "[-1.2223e+02  3.7880e+01  4.1000e+01  8.8000e+02  1.2900e+02  3.2200e+02\n",
      "  1.2600e+02  8.3252e+00  4.5260e+05]\n",
      "\n",
      "Shuffled incides: [14740 10101 20566 ...  9845 10799  2732]\n",
      "Check whether shuffling done correctly, next 2 rows should be the same:\n",
      "[-117.05     32.58     22.     2101.      399.     1551.      371.\n",
      "    4.1518]\n",
      "[-1.1918e+02  3.4160e+01  1.2000e+01  4.6000e+02  1.0100e+02  4.0500e+02\n",
      "  1.0300e+02  5.2783e+00  1.6740e+05]\n",
      "\n",
      "Size of trainset: 14448\n",
      "Size of testset: 6192\n",
      "\n",
      "Before normalization: [-119.79    36.73    52.     112.      28.     193.      40.       1.975]\n",
      "Normalized: [-0.11131397  0.51396387  1.8562098  -1.15358908 -1.2069376  -1.07186955\n",
      " -1.1994956  -1.00030408]\n"
     ]
    }
   ],
   "source": [
    "SEED = 0\n",
    "# Load and view the dataset\n",
    "cal_housing = np.loadtxt('data/cal_housing.data', delimiter=',')\n",
    "print(\"Dataset dimensions: \" + str(cal_housing.shape)) # 20640 observations, 8 + 1 variables, last var is the dependent var\n",
    "print(\"First row:\")\n",
    "print(cal_housing[0].view())\n",
    "\n",
    "# Split into inputs and labels\n",
    "X_data, Y_data = cal_housing[:,:8], cal_housing[:,-1] \n",
    "Y_data = (np.asmatrix(Y_data)).transpose()\n",
    "\n",
    "# Shuffle data to break any symmetry\n",
    "idx = np.arange(X_data.shape[0]) # no of rows\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(idx)\n",
    "print(\"\\nShuffled incides: \" + str(idx))\n",
    "X_data, Y_data = X_data[idx], Y_data[idx] \n",
    "\n",
    "print(\"Check whether shuffling done correctly, next 2 rows should be the same:\")\n",
    "print(X_data[0].view())\n",
    "print(cal_housing[20303].view())\n",
    "\n",
    "# Read and divide data into test and train sets \n",
    "m = 3* X_data.shape[0] // 10\n",
    "n = 7* X_data.shape[0] // 10\n",
    "trainX, trainY = X_data[m:], Y_data[m:] # take the back 70% for trainset\n",
    "testX, testY = X_data[:m], Y_data[:m] # take the front 30% for testset\n",
    "print(\"\\nSize of trainset: \" + str(len(trainX)))\n",
    "print(\"Size of testset: \" + str(len(testX)))\n",
    "\n",
    "# Normalize input\n",
    "print(\"\\nBefore normalization: \" + str(trainX[0]))\n",
    "trainX = (trainX- np.mean(trainX, axis=0))/ np.std(trainX, axis=0)\n",
    "testX = (testX- np.mean(testX, axis=0))/ np.std(testX, axis=0)\n",
    "print(\"Normalized: \" + str(trainX[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=10e-6)\n",
    "num_epoch = 500\n",
    "def model_init_fn(inputs, is_training):\n",
    "    hidden_layer_size, num_classes = 10, 6\n",
    "    initializer = tf.variance_scaling_initializer(scale=1.0, seed=0)\n",
    "    layers = [\n",
    "        tf.layers.Dense(hidden_layer_size, activation=tf.nn.sigmoid,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        kernel_initializer=initializer),\n",
    "        tf.layers.Dense(num_classes,\n",
    "                        kernel_regularizer=regularizer,\n",
    "                        kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "errors, accuracies = train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epoch)\n",
    "# print(errors, accuracies)\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(nrows=2, ncols=1)\n",
    "ax1.plot(range(len(errors)), errors)\n",
    "ax2.plot(range(len(accuracies)), accuracies)\n",
    "plt.xlabel('epoch')\n",
    "ax1.set_ylabel('Train Errors')\n",
    "ax2.set_ylabel('Validation accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
